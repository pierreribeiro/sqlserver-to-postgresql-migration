# üìä SQL Server Dependency Analysis - Lote 4: User-Defined Types
## Perseus Database Migration Project - DinamoTech

**Analysis Date:** 2025-12-15  
**Analyst:** Pierre Ribeiro + Claude (Database Expert)  
**Scope:** 1 User-Defined Table Type in Perseus Database  
**Repository:** pierreribeiro/sqlserver-to-postgresql-migration

---

## üéØ Executive Summary

This document provides comprehensive dependency analysis of the user-defined table type (TVP - Table-Valued Parameter) in the Perseus SQL Server database. The type has been analyzed to identify:
- **Complete structure and definition**
- **WHAT uses it** (Functions and Stored Procedures)
- **Migration complexity and strategies**
- **PostgreSQL conversion options with detailed implementation**

### Key Findings

| Category | Detail | Impact |
|----------|--------|--------|
| **Total Types Analyzed** | 1 | GooList (100% coverage) |
| **Type Category** | Table-Valued Parameter (TVP) | No native PostgreSQL equivalent |
| **Structure** | Single column: uid NVARCHAR(50), PRIMARY KEY | Ensures uniqueness in batch operations |
| **Used by P0 Functions** | 2 | McGetUpStreamByList, McGetDownStreamByList |
| **Used by P0 Stored Procedures** | 2 | ReconcileMUpstream, ProcessSomeMUpstream |
| **PostgreSQL Conversion Options** | 3 | TEMP TABLE (recommended), ARRAY, JSONB |
| **Migration Complexity** | HIGH | Requires function signature changes |

### Critical Discovery

**Type `GooList` is CRITICAL for batch processing operations:**
- Used by P0 reconciliation engine (`ReconcileMUpstream`) ‚≠ê‚≠ê‚≠ê
- Used by P1 batch processor (`ProcessSomeMUpstream`) ‚≠ê‚≠ê
- Enables efficient batch lineage calculation for multiple materials simultaneously
- Has PRIMARY KEY constraint ensuring uniqueness (no duplicate UIDs)
- PostgreSQL has NO native Table-Valued Parameters
- Conversion strategy MUST be decided before function migration
- Recommended: TEMPORARY TABLE pattern for minimal code changes

---

## üìã Detailed Type Analysis

### 1. User-Defined Table Type ‚≠ê‚≠ê‚≠ê **P0 CRITICAL**

#### 1.1 `dbo.GooList` ‚≠ê‚≠ê‚≠ê **TABLE-VALUED PARAMETER TYPE**

**Purpose:** Table-Valued Parameter for batch material processing operations. Enables passing a set of material UIDs to functions/procedures for bulk lineage calculations.

**Complete SQL Server Definition:**
```sql
CREATE TYPE [dbo].[GooList] AS TABLE(
    [uid] [nvarchar](50) COLLATE SQL_Latin1_General_CP1_CI_AS NOT NULL,
    PRIMARY KEY CLUSTERED 
(
    [uid] ASC
)WITH (IGNORE_DUP_KEY = OFF)
)
GO
```

**Structure Details:**

| Component | Value | Significance |
|-----------|-------|--------------|
| **Column Name** | `uid` | Material unique identifier |
| **Data Type** | `NVARCHAR(50)` | Unicode string, max 50 characters |
| **Collation** | `SQL_Latin1_General_CP1_CI_AS` | Case-insensitive, accent-sensitive |
| **Constraint** | `NOT NULL` | UIDs required, no nulls allowed |
| **Primary Key** | `CLUSTERED` on `uid ASC` | Ensures uniqueness, orders by uid |
| **Duplicate Handling** | `IGNORE_DUP_KEY = OFF` | Errors on duplicate inserts |

**Key Characteristics:**

1. **PRIMARY KEY CLUSTERED:**
   - Ensures NO duplicate UIDs in batch
   - Orders data by uid (performance optimization)
   - Physical storage ordering in SQL Server

2. **IGNORE_DUP_KEY = OFF:**
   - If duplicate uid inserted ‚Üí ERROR raised
   - Strict uniqueness enforcement
   - Caller must ensure unique UIDs before passing

3. **NVARCHAR vs VARCHAR:**
   - NVARCHAR = Unicode (2 bytes per character)
   - Supports international characters
   - PostgreSQL: TEXT or VARCHAR (UTF-8 by default)

4. **READONLY Parameter Semantics:**
   - TVPs are always READONLY in SQL Server
   - Cannot be modified inside function/procedure
   - Input-only, no output capability

**Dependencies - WHAT it references:**
- **None** - It's a type definition, doesn't reference other objects

**Referenced By - WHO references it:**

**Functions (from Lote 2):**

1. **`dbo.McGetUpStreamByList()`** ‚≠ê‚≠ê‚≠ê **P0 CRITICAL**
   - **Signature:** `CREATE FUNCTION McGetUpStreamByList(@StartPoint GooList READONLY)`
   - **Usage Pattern:**
     ```sql
     -- Join to table parameter
     FROM translated pt
     JOIN @StartPoint sp ON sp.uid = pt.destination_material
     
     -- Select from table parameter  
     INSERT INTO @Paths
     SELECT sp.uid, sp.uid, NULL, '', 0
     FROM @StartPoint sp
     WHERE EXISTS (SELECT 1 FROM goo WHERE sp.uid = goo.uid)
     ```
   - **Purpose:** Batch upstream lineage calculation for multiple materials
   - **Performance:** Processes N materials in single call vs N individual calls
   - **Complexity:** 9/10

2. **`dbo.McGetDownStreamByList()`** ‚≠ê‚≠ê **P1 HIGH**
   - **Signature:** `CREATE FUNCTION McGetDownStreamByList(@StartPoint GooList READONLY)`
   - **Usage Pattern:** Similar to McGetUpStreamByList (downstream direction)
   - **Purpose:** Batch downstream lineage calculation
   - **Complexity:** 8/10

**Stored Procedures (from Lote 1):**

1. **`dbo.ReconcileMUpstream`** ‚≠ê‚≠ê‚≠ê **P0 CRITICAL**
   - **Usage Context:**
     ```sql
     DECLARE @dirty_in GooList
     DECLARE @clean_in GooList
     
     -- Populate dirty_in with UIDs from m_upstream_dirty_leaves
     INSERT INTO @dirty_in (uid)
     SELECT TOP 10 uid FROM m_upstream_dirty_leaves
     
     -- Call function with two GooList parameters
     EXEC McGetUpStreamByList @dirty_in, @clean_in
     ```
   - **Pattern:** Creates TWO GooList variables (dirty + clean materials)
   - **Business Impact:** Core reconciliation engine for material lineage
   - **Frequency:** Scheduled job (high frequency)

2. **`dbo.ProcessSomeMUpstream`** ‚≠ê‚≠ê **P1 HIGH**
   - **Usage Context:**
     ```sql
     DECLARE @dirty_in GooList READONLY
     DECLARE @clean_in GooList READONLY
     
     -- Filter and process batch of materials
     -- Calls McGetUpStreamByList(@dirty_in, @clean_in)
     ```
   - **Pattern:** Batch processing with filtered material lists
   - **Business Impact:** Bulk update processor for upstream relationships
   - **Frequency:** On-demand or scheduled

**Typical Batch Sizes (inferred from code):**
- ReconcileMUpstream: TOP 10 materials per batch
- ProcessSomeMUpstream: Variable (could be larger batches)
- Function design: Supports any batch size (no hardcoded limits)

**Complexity Score:** 5/10 (simple structure, complex migration implications)  
**Business Criticality:** P0 CRITICAL - Used by core batch operations  
**Migration Impact:** HIGH - No native PostgreSQL equivalent

---

## üîó Dependency Graph Summary

### Complete Type Usage Chain

```
1. P0 Reconciliation Chain:
   Scheduled Job (Reconciliation)
   ‚îî‚îÄ> SP: dbo.ReconcileMUpstream ‚≠ê‚≠ê‚≠ê
       ‚îú‚îÄ> DECLARE @dirty_in GooList
       ‚îú‚îÄ> DECLARE @clean_in GooList
       ‚îî‚îÄ> FUNCTION: McGetUpStreamByList(@dirty_in, @clean_in) ‚≠ê‚≠ê‚≠ê
           ‚îî‚îÄ> VIEW: translated ‚≠ê‚≠ê‚≠ê‚≠ê
               ‚îî‚îÄ> TABLES: material_transition, transition_material

2. P1 Batch Processing Chain:
   Batch Job / Application
   ‚îî‚îÄ> SP: dbo.ProcessSomeMUpstream ‚≠ê‚≠ê
       ‚îú‚îÄ> DECLARE @dirty_in GooList READONLY
       ‚îú‚îÄ> DECLARE @clean_in GooList READONLY
       ‚îî‚îÄ> FUNCTION: McGetUpStreamByList(@dirty_in, @clean_in) ‚≠ê‚≠ê‚≠ê

3. Future/Optional Chain:
   Applications
   ‚îî‚îÄ> FUNCTION: McGetDownStreamByList(@StartPoint GooList) ‚≠ê‚≠ê
       ‚îî‚îÄ> VIEW: translated ‚≠ê‚≠ê‚≠ê‚≠ê
```

### Usage Matrix

| Object | Type | Uses GooList | Pattern | Priority |
|--------|------|--------------|---------|----------|
| McGetUpStreamByList | Function | ‚úÖ Parameter | JOIN + SELECT | ‚≠ê‚≠ê‚≠ê P0 |
| McGetDownStreamByList | Function | ‚úÖ Parameter | JOIN + SELECT | ‚≠ê‚≠ê P1 |
| ReconcileMUpstream | SP | ‚úÖ Local Variable | DECLARE + INSERT + Pass to function | ‚≠ê‚≠ê‚≠ê P0 |
| ProcessSomeMUpstream | SP | ‚úÖ Local Variable | DECLARE + INSERT + Pass to function | ‚≠ê‚≠ê P1 |

---

## üéØ Critical Observations & PostgreSQL Migration Strategies

### 1. **No Native Table-Valued Parameters in PostgreSQL** ‚ö†Ô∏è

**Issue:**
- SQL Server: TVPs are first-class database objects (CREATE TYPE)
- PostgreSQL: No native equivalent for TABLE types as parameters

**Impact:**
- Function signatures must change
- Calling code must change
- Three conversion strategies available (detailed below)

---

### 2. **PostgreSQL Conversion Strategy Analysis**

We have THREE options for converting GooList to PostgreSQL. Each has tradeoffs:

---

#### **OPTION 1: TEMPORARY TABLE Pattern** ‚≠ê **RECOMMENDED**

**Implementation:**

```sql
-- PostgreSQL: Functions receive table name as TEXT parameter
CREATE OR REPLACE FUNCTION mcget_upstream_by_list(
    p_temp_table_name TEXT  -- Name of temp table with UIDs
)
RETURNS TABLE (
    start_point VARCHAR(50),
    end_point VARCHAR(50),
    neighbor VARCHAR(50),
    path VARCHAR(500),
    level INTEGER
)
LANGUAGE plpgsql
AS $$
BEGIN
    -- Query the temp table by name using EXECUTE
    RETURN QUERY EXECUTE format('
        WITH RECURSIVE upstream AS (
            SELECT 
                pt.destination_material AS start_point,
                pt.destination_material AS parent,
                pt.source_material AS child,
                ''/''::VARCHAR(500) AS path,
                1 AS level
            FROM translated pt
            JOIN %I sp ON sp.uid = pt.destination_material
            UNION ALL
            SELECT 
                r.start_point,
                pt.destination_material,
                pt.source_material,
                (r.path || r.child || ''/'')::VARCHAR(500),
                r.level + 1
            FROM translated pt
            JOIN upstream r ON pt.destination_material = r.child
            WHERE pt.destination_material != pt.source_material
        )
        SELECT start_point, child AS end_point, parent, path, level 
        FROM upstream
        UNION ALL
        SELECT uid, uid, NULL, '''', 0 
        FROM %I sp
        WHERE EXISTS (SELECT 1 FROM goo WHERE sp.uid = goo.uid)
    ', p_temp_table_name, p_temp_table_name);
END;
$$;

-- Calling pattern from stored procedure:
CREATE OR REPLACE PROCEDURE reconcile_m_upstream()
LANGUAGE plpgsql
AS $$
BEGIN
    -- Create temp table (session-scoped)
    CREATE TEMP TABLE temp_dirty_in (
        uid VARCHAR(50) NOT NULL PRIMARY KEY
    ) ON COMMIT DROP;
    
    CREATE TEMP TABLE temp_clean_in (
        uid VARCHAR(50) NOT NULL PRIMARY KEY
    ) ON COMMIT DROP;
    
    -- Populate temp tables
    INSERT INTO temp_dirty_in (uid)
    SELECT uid FROM m_upstream_dirty_leaves LIMIT 10;
    
    -- Call function with temp table names
    PERFORM * FROM mcget_upstream_by_list('temp_dirty_in');
    
    -- Temp tables auto-dropped at transaction end
END;
$$;
```

**Pros:**
- ‚úÖ Most similar to SQL Server behavior
- ‚úÖ Supports PRIMARY KEY constraints (uniqueness)
- ‚úÖ Best performance for large batches (indexed temp table)
- ‚úÖ Natural SQL syntax (JOIN to temp table)
- ‚úÖ Session-scoped (isolated between connections)

**Cons:**
- ‚ùå Function signature changes (table name vs data)
- ‚ùå Requires EXECUTE + format() for dynamic SQL
- ‚ùå More verbose calling code
- ‚ùå Temp table management overhead

**When to Use:** 
- Large batch sizes (100+ UIDs)
- Complex queries (multiple JOINs to same batch)
- Need for PRIMARY KEY constraint enforcement

---

#### **OPTION 2: ARRAY Parameter** üî∂ **SIMPLER BUT LIMITED**

**Implementation:**

```sql
-- PostgreSQL: Functions receive ARRAY of VARCHAR
CREATE OR REPLACE FUNCTION mcget_upstream_by_list(
    p_uids VARCHAR(50)[]  -- Array of UIDs
)
RETURNS TABLE (
    start_point VARCHAR(50),
    end_point VARCHAR(50),
    neighbor VARCHAR(50),
    path VARCHAR(500),
    level INTEGER
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    WITH RECURSIVE upstream AS (
        SELECT 
            pt.destination_material AS start_point,
            pt.destination_material AS parent,
            pt.source_material AS child,
            '/'::VARCHAR(500) AS path,
            1 AS level
        FROM translated pt
        WHERE pt.destination_material = ANY(p_uids)  -- Array membership
        UNION ALL
        SELECT 
            r.start_point,
            pt.destination_material,
            pt.source_material,
            (r.path || r.child || '/')::VARCHAR(500),
            r.level + 1
        FROM translated pt
        JOIN upstream r ON pt.destination_material = r.child
        WHERE pt.destination_material != pt.source_material
    )
    SELECT start_point, child AS end_point, parent, path, level 
    FROM upstream
    UNION ALL
    SELECT uid, uid, NULL::VARCHAR(50), '', 0
    FROM unnest(p_uids) AS uid
    WHERE EXISTS (SELECT 1 FROM goo WHERE goo.uid = uid);
END;
$$;

-- Calling pattern from stored procedure:
CREATE OR REPLACE PROCEDURE reconcile_m_upstream()
LANGUAGE plpgsql
AS $$
DECLARE
    v_dirty_uids VARCHAR(50)[];
    v_clean_uids VARCHAR(50)[];
BEGIN
    -- Populate arrays
    SELECT ARRAY_AGG(uid) INTO v_dirty_uids
    FROM (SELECT uid FROM m_upstream_dirty_leaves LIMIT 10) t;
    
    v_clean_uids := ARRAY[]::VARCHAR(50)[];  -- Empty array
    
    -- Call function with arrays
    PERFORM * FROM mcget_upstream_by_list(v_dirty_uids);
END;
$$;
```

**Pros:**
- ‚úÖ Simpler syntax (no temp table management)
- ‚úÖ Cleaner function signature
- ‚úÖ Native PostgreSQL array operations (ANY, unnest)
- ‚úÖ Less code overall

**Cons:**
- ‚ùå No PRIMARY KEY constraint (duplicates allowed)
- ‚ùå Performance degrades with large arrays (1000+ elements)
- ‚ùå Memory usage increases with array size
- ‚ùå Less SQL-like (unnest() is less intuitive than JOIN)

**When to Use:**
- Small to medium batch sizes (<100 UIDs)
- Simple queries (single use of parameter)
- Uniqueness not critical (handled by caller)

---

#### **OPTION 3: JSONB Parameter** üî∑ **MODERN BUT OVERKILL**

**Implementation:**

```sql
-- PostgreSQL: Functions receive JSONB array
CREATE OR REPLACE FUNCTION mcget_upstream_by_list(
    p_uids_json JSONB  -- JSONB array: ["m123", "m456", ...]
)
RETURNS TABLE (
    start_point VARCHAR(50),
    end_point VARCHAR(50),
    neighbor VARCHAR(50),
    path VARCHAR(500),
    level INTEGER
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    WITH uids AS (
        SELECT jsonb_array_elements_text(p_uids_json) AS uid
    ),
    RECURSIVE upstream AS (
        SELECT 
            pt.destination_material AS start_point,
            pt.destination_material AS parent,
            pt.source_material AS child,
            '/'::VARCHAR(500) AS path,
            1 AS level
        FROM translated pt
        JOIN uids sp ON sp.uid = pt.destination_material
        UNION ALL
        SELECT 
            r.start_point,
            pt.destination_material,
            pt.source_material,
            (r.path || r.child || '/')::VARCHAR(500),
            r.level + 1
        FROM translated pt
        JOIN upstream r ON pt.destination_material = r.child
        WHERE pt.destination_material != pt.source_material
    )
    SELECT start_point, child AS end_point, parent, path, level 
    FROM upstream
    UNION ALL
    SELECT uid, uid, NULL::VARCHAR(50), '', 0
    FROM uids
    WHERE EXISTS (SELECT 1 FROM goo WHERE goo.uid = uids.uid);
END;
$$;

-- Calling pattern:
CREATE OR REPLACE PROCEDURE reconcile_m_upstream()
LANGUAGE plpgsql
AS $$
DECLARE
    v_dirty_json JSONB;
BEGIN
    -- Build JSONB array
    SELECT jsonb_agg(uid) INTO v_dirty_json
    FROM (SELECT uid FROM m_upstream_dirty_leaves LIMIT 10) t;
    
    -- Call function
    PERFORM * FROM mcget_upstream_by_list(v_dirty_json);
END;
$$;
```

**Pros:**
- ‚úÖ Modern, flexible format
- ‚úÖ Good for REST API integration
- ‚úÖ Supports complex structures (if needed in future)
- ‚úÖ JSON validation available

**Cons:**
- ‚ùå Overkill for simple list of UIDs
- ‚ùå Extra serialization/deserialization overhead
- ‚ùå Less readable than ARRAY or temp table
- ‚ùå No PRIMARY KEY constraint

**When to Use:**
- API-driven architecture (REST/JSON)
- Future extensibility needed (add metadata to UIDs)
- Already using JSONB heavily in application

---

### 3. **Recommended Strategy: TEMPORARY TABLE** ‚≠ê

**Rationale:**

1. **Closest to SQL Server Semantics:**
   - PRIMARY KEY constraint preserved
   - Table-like behavior maintained
   - Natural SQL JOINs

2. **Performance:**
   - Best for large batches (ReconcileMUpstream could grow)
   - Indexed temp table = fast lookups
   - No array size limitations

3. **Code Clarity:**
   - Explicit temp table creation = clear intent
   - Standard SQL syntax (no unnest/jsonb functions)
   - Easy to debug (can query temp table directly)

4. **Future-Proof:**
   - Easy to add columns to temp table if needed
   - Supports multiple columns (if GooList evolves)
   - Familiar pattern for DBAs

**Implementation Plan:**

1. **Phase 1:** Create temp table wrapper functions
   ```sql
   CREATE OR REPLACE FUNCTION create_goolist_temp(p_table_name TEXT)
   RETURNS VOID AS $$
   BEGIN
       EXECUTE format('
           CREATE TEMP TABLE IF NOT EXISTS %I (
               uid VARCHAR(50) NOT NULL PRIMARY KEY
           ) ON COMMIT DROP
       ', p_table_name);
   END;
   $$ LANGUAGE plpgsql;
   ```

2. **Phase 2:** Convert functions to accept temp table names

3. **Phase 3:** Convert stored procedures to use temp tables

4. **Phase 4:** Test with production-scale batches

---

### 4. **NVARCHAR vs VARCHAR Conversion**

**SQL Server:**
```sql
[uid] NVARCHAR(50)  -- Unicode, 2 bytes per character
```

**PostgreSQL:**
```sql
uid VARCHAR(50)  -- UTF-8 encoding (1-4 bytes per character)
-- OR
uid TEXT  -- Unlimited length, UTF-8
```

**Recommendation:** Use `VARCHAR(50)` in PostgreSQL
- PostgreSQL VARCHAR is already UTF-8 (Unicode support)
- No need for separate NVARCHAR type
- Same character limit (50)

---

### 5. **PRIMARY KEY Constraint Migration**

**SQL Server:**
```sql
PRIMARY KEY CLUSTERED (uid ASC)
WITH (IGNORE_DUP_KEY = OFF)
```

**PostgreSQL:**
```sql
-- For TEMP TABLE pattern:
CREATE TEMP TABLE temp_goolist (
    uid VARCHAR(50) NOT NULL PRIMARY KEY
);

-- CLUSTERED index not needed (PostgreSQL uses heap storage by default)
-- IGNORE_DUP_KEY = OFF is default (errors on duplicate)
```

**Behavior Differences:**
- SQL Server CLUSTERED = physical ordering
- PostgreSQL PRIMARY KEY = unique B-tree index (no physical clustering)
- Both enforce uniqueness equally
- Both error on duplicate inserts (IGNORE_DUP_KEY = OFF equivalent)

---

### 6. **Collation Handling**

**SQL Server:**
```sql
COLLATE SQL_Latin1_General_CP1_CI_AS
-- CI = Case Insensitive
-- AS = Accent Sensitive
```

**PostgreSQL:**
```sql
-- Set at database level or column level
uid VARCHAR(50) COLLATE "en_US.utf8"

-- For case-insensitive comparisons:
WHERE LOWER(uid) = LOWER(input_uid)

-- OR use citext extension:
CREATE EXTENSION citext;
uid CITEXT  -- Case-insensitive text type
```

**Recommendation:**
- Use standard VARCHAR(50) 
- Material UIDs are likely case-sensitive (e.g., 'm123' != 'M123')
- If case-insensitive needed, use LOWER() in WHERE clauses
- Avoid citext unless required (adds complexity)

---

## üìä Migration Priority Matrix

### P0 - ABSOLUTE CRITICAL (Sprint 9 - Before Functions)

| Object | Reason | Depends On | Blocks |
|--------|--------|------------|--------|
| **GooList Type** | Used by P0 functions & SPs | None (foundational) | McGetUpStreamByList, McGetDownStreamByList, ReconcileMUpstream, ProcessSomeMUpstream |

**Timeline:** MUST be completed BEFORE McGet*ByList functions migration  
**Strategy Decision:** MUST be decided in Sprint 9 Week 1  
**Testing:** Proof-of-concept with small batch (10 UIDs) then production scale (100+ UIDs)

---

## üîÑ Migration Strategy Recommendations

### Phase 1: Strategy Decision & POC (Sprint 9 Week 1)

**Step 1: Decide on Conversion Strategy**
- **Recommendation:** TEMPORARY TABLE pattern
- **Validation:** Prototype all 3 options with 10-row test
- **Benchmark:** Compare performance (temp table vs array vs jsonb)
- **Decision Criteria:** Performance + code clarity + maintainability

**Step 2: Create PostgreSQL Type Wrapper (if temp table pattern)**
```sql
-- Helper function to create standard GooList temp table
CREATE OR REPLACE FUNCTION create_goolist_temp_table(p_table_name TEXT)
RETURNS VOID
LANGUAGE plpgsql
AS $$
BEGIN
    EXECUTE format('
        CREATE TEMP TABLE IF NOT EXISTS %I (
            uid VARCHAR(50) NOT NULL PRIMARY KEY
        ) ON COMMIT DROP
    ', p_table_name);
END;
$$;

-- Usage in procedures:
PERFORM create_goolist_temp_table('temp_dirty_in');
INSERT INTO temp_dirty_in (uid) VALUES ('m123'), ('m456');
```

**Step 3: Test with Small Batch**
- Create temp table with 10 UIDs
- Call converted function
- Validate results match SQL Server
- Check performance metrics

---

### Phase 2: Function Migration (Sprint 9 Week 2)

**Step 1: Convert McGetUpStreamByList**
```sql
-- Before (SQL Server):
CREATE FUNCTION McGetUpStreamByList(@StartPoint GooList READONLY)

-- After (PostgreSQL - temp table pattern):
CREATE FUNCTION mcget_upstream_by_list(p_temp_table_name TEXT)
```

**Step 2: Convert McGetDownStreamByList**
- Same pattern as McGetUpStreamByList

**Step 3: Integration Testing**
- Test with ReconcileMUpstream (P0 SP)
- Test with ProcessSomeMUpstream (P1 SP)
- Validate lineage calculation results

---

### Phase 3: Stored Procedure Migration (Sprint 10)

**Step 1: Update ReconcileMUpstream**
```sql
-- Add temp table creation logic
CREATE TEMP TABLE temp_dirty_in (...);
CREATE TEMP TABLE temp_clean_in (...);

-- Populate temp tables
INSERT INTO temp_dirty_in SELECT ...;

-- Call function with temp table name
PERFORM * FROM mcget_upstream_by_list('temp_dirty_in');
```

**Step 2: Update ProcessSomeMUpstream**
- Same pattern as ReconcileMUpstream

**Step 3: End-to-End Testing**
- Test scheduled job execution
- Test with production-scale batches
- Performance validation

---

### Phase 4: Performance Optimization (Sprint 11)

**Step 1: Batch Size Tuning**
- Current: TOP 10 per batch (ReconcileMUpstream)
- Test: 10, 50, 100, 500 UIDs per batch
- Find optimal batch size for PostgreSQL

**Step 2: Temp Table Index Strategy**
- PRIMARY KEY already creates B-tree index
- Consider additional indexes if needed
- Monitor query plans

**Step 3: Memory Configuration**
- Adjust work_mem for large batches
- Monitor temp table disk usage
- Tune temp_buffers if needed

---

## üîó Integration with Lotes 1, 2, 3 Analysis

### Complete Cross-Lote Dependency Validation

```
FOUNDATIONAL LAYER (Lote 4):
TYPE GooList ‚≠ê‚≠ê‚≠ê‚≠ê
‚îÇ
‚îú‚îÄ> FUNCTIONS (Lote 2):
‚îÇ   ‚îú‚îÄ> McGetUpStreamByList() ‚≠ê‚≠ê‚≠ê P0
‚îÇ   ‚îî‚îÄ> McGetDownStreamByList() ‚≠ê‚≠ê P1
‚îÇ       ‚îî‚îÄ> VIEW translated ‚≠ê‚≠ê‚≠ê‚≠ê (Lote 3)
‚îÇ           ‚îî‚îÄ> TABLES: material_transition, transition_material
‚îÇ
‚îî‚îÄ> STORED PROCEDURES (Lote 1):
    ‚îú‚îÄ> ReconcileMUpstream ‚≠ê‚≠ê‚≠ê P0
    ‚îî‚îÄ> ProcessSomeMUpstream ‚≠ê‚≠ê P1
        ‚îî‚îÄ> Call McGetUpStreamByList()
```

**Critical Path Impact:**
- GooList is at the FOUNDATION of the P0 critical path
- Must be migrated FIRST (before functions)
- Conversion strategy affects ALL dependent functions/SPs
- Any performance issues cascade to entire batch processing system

**Migration Order (STRICT):**
1. ‚úÖ **Lote 3:** VIEW translated (MATERIALIZED VIEW)
2. ‚è≠Ô∏è **Lote 4:** TYPE GooList (TEMP TABLE pattern)
3. ‚è≠Ô∏è **Lote 2:** FUNCTIONS McGet*ByList (using temp tables)
4. ‚è≠Ô∏è **Lote 1:** SPs ReconcileMUpstream, ProcessSomeMUpstream

---

## üîÑ Next Steps

### Immediate Actions:
1. ‚úÖ **Lote 1 Complete:** 21 Stored Procedures analyzed
2. ‚úÖ **Lote 2 Complete:** 24 Functions analyzed
3. ‚úÖ **Lote 3 Complete:** 22 Views analyzed
4. ‚úÖ **Lote 4 Complete:** 1 Type (GooList) analyzed
5. ‚è≠Ô∏è **FINAL DOCUMENT:** Create consolidated dependency tree with visual Mermaid diagram

### Questions for Stakeholders:

1. **Batch Size Strategy:**
   - What is the typical batch size for ReconcileMUpstream? (currently TOP 10)
   - What is the maximum batch size expected in production?
   - Should we increase batch size for better performance?

2. **Performance Requirements:**
   - What is the acceptable execution time for batch processing?
   - Current SQL Server performance baseline?
   - SLA for reconciliation job completion?

3. **Testing Strategy:**
   - Can we get production data sample for testing? (anonymized UIDs)
   - What is the test environment setup timeline?
   - Who validates lineage calculation correctness?

4. **Conversion Strategy Preference:**
   - Do stakeholders have preference: TEMP TABLE vs ARRAY vs JSONB?
   - Any concerns about EXECUTE + format() dynamic SQL?
   - Application compatibility considerations?

---

## üìå Document Metadata

**Version:** 1.0  
**Last Updated:** 2025-12-15  
**Next Review:** Final Consolidated Dependency Tree  
**Maintained By:** Pierre Ribeiro (Senior DBA/DBRE)  
**Project:** Perseus Database Migration - SQL Server ‚Üí PostgreSQL 17  
**Dependencies:** Lote 1 (Stored Procedures), Lote 2 (Functions), Lote 3 (Views)

---

## üìö Appendix: Conversion Strategy Comparison Matrix

| Criterion | TEMP TABLE ‚≠ê | ARRAY | JSONB |
|-----------|--------------|-------|-------|
| **Performance (small batch <100)** | Good | Excellent | Good |
| **Performance (large batch >100)** | Excellent | Poor | Good |
| **Code Complexity** | Medium | Low | Medium |
| **SQL Server Similarity** | High | Low | Low |
| **PRIMARY KEY Support** | ‚úÖ Yes | ‚ùå No | ‚ùå No |
| **Memory Usage** | Low (disk-backed) | High (in-memory) | Medium |
| **Query Plan Optimization** | Excellent | Poor | Good |
| **Debugging Ease** | Excellent | Medium | Medium |
| **Future Extensibility** | Excellent | Poor | Excellent |
| **Learning Curve** | Low | Medium | High |
| **RECOMMENDATION** | ‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê |

**Winner:** TEMPORARY TABLE pattern for production use.

---

**End of Lote 4 Analysis**
