# An√°lise Qualitativa: Convers√£o T-SQL ‚Üí PL/pgSQL
## AWS Schema Conversion Tool - ReconcileMUpstream Procedure

**Analisado por:** Pierre Ribeiro (Database Reliability Engineer)  
**Data:** 2025-11-12  
**Ferramenta:** AWS Schema Conversion Tool (SCT)  
**Origem:** SQL Server Enterprise 2014 (T-SQL)  
**Destino:** PostgreSQL (PL/pgSQL)  
**Procedure:** `dbo.ReconcileMUpstream`

---

## üìä Executive Summary

| M√©trica | Score | Status |
|---------|-------|--------|
| **Corre√ß√£o L√≥gica** | 7/10 | ‚úÖ BOM |
| **Corre√ß√£o Sint√°tica** | 5/10 | ‚ö†Ô∏è PROBLEMAS CR√çTICOS |
| **Performance** | 6/10 | ‚ö†Ô∏è OTIMIZA√á√ïES NECESS√ÅRIAS |
| **Manutenibilidade** | 7/10 | ‚úÖ BOM |
| **Seguran√ßa** | 8/10 | ‚úÖ BOM |
| **SCORE GERAL** | **6.6/10 (66%)** | ‚ö†Ô∏è **N√ÉO PRODUCTION-READY** |

### üéØ Veredito Final

‚ùå **N√ÉO est√° production-ready** - Cont√©m erros cr√≠ticos que impedem execu√ß√£o  
‚úÖ **√â um bom ponto de partida** - ~70% do trabalho foi feito corretamente  
‚ö†Ô∏è **Requer revis√£o manual obrigat√≥ria** - Problemas P0 devem ser corrigidos antes de deploy

---

## üîç 1. Mapeamento de Convers√µes

### 1.1 Table Variables ‚Üí Temporary Tables

**SQL Server (T-SQL):**
```sql
DECLARE @OldUpstream TABLE(
    start_point VARCHAR(50),
    end_point VARCHAR(50),
    path VARCHAR(500),
    level INT,
    PRIMARY KEY (start_point, end_point, path)
)
```

**PostgreSQL (PL/pgSQL):**
```sql
CREATE TEMPORARY TABLE oldupstream$reconcilemupstream (
    start_point VARCHAR(50),
    end_point VARCHAR(50),
    path VARCHAR(500),
    level INTEGER,
    PRIMARY KEY (start_point, end_point, path)
)
```

**An√°lise:**
- ‚úÖ Convers√£o estruturalmente correta
- ‚ö†Ô∏è Nomenclatura estranha: `oldupstream$reconcilemupstream` (deveria ser `old_upstream`)
- ‚ö†Ô∏è **Warning AWS SCT [7659]:** Difference in scope between table variables (batch-scoped) and temp tables (session-scoped)

---

### 1.2 Transaction Control

**SQL Server (T-SQL):**
```sql
BEGIN TRY
    BEGIN TRANSACTION
        -- business logic
    COMMIT TRANSACTION
END TRY
BEGIN CATCH
    ROLLBACK TRANSACTION
    RAISERROR (@ErrorMessage, @ErrorSeverity, @ErrorState)
END CATCH
```

**PostgreSQL (PL/pgSQL):**
```sql
/*
[7807 - Severity CRITICAL - PostgreSQL does not support explicit transaction 
management commands such as BEGIN TRAN, SAVE TRAN in functions. Convert your 
source code manually.]
BEGIN TRANSACTION
*/
DECLARE ... BEGIN
    -- business logic
    /*
    [7615 - Severity CRITICAL - Your code ends a transaction inside a block 
    with exception handlers. Revise your code to move transaction control 
    to the application side and try again.]
    COMMIT TRANSACTION
    */
    EXCEPTION
        WHEN OTHERS THEN
            ROLLBACK;
            RAISE 'Error %...';
END;
```

**An√°lise:**
- ‚ùå **CR√çTICO:** Transaction control foi **REMOVIDO** mas ROLLBACK foi mantido
- ‚ùå **ERRO DE EXECU√á√ÉO:** ROLLBACK sem BEGIN gera erro em runtime
- ‚ö†Ô∏è AWS SCT marcou como CRITICAL mas n√£o corrigiu adequadamente
- üí° **Solu√ß√£o:** PostgreSQL PROCEDURES (n√£o functions) suportam transaction control expl√≠cito

---

### 1.3 String Comparisons

**SQL Server (T-SQL):**
```sql
WHERE material_uid != 'n/a'
```

**PostgreSQL (PL/pgSQL):**
```sql
WHERE LOWER(material_uid) != LOWER('n/a')
/*
[7795 - Severity LOW - In PostgreSQL, string operations are case sensitive. 
Review the converted code to make sure that it compares strings correctly.]
material_uid != 'n/a'
*/
```

**An√°lise:**
- ‚ö†Ô∏è SCT adicionou `LOWER()` em **13 ocorr√™ncias**
- ‚ö†Ô∏è **Performance Impact:** LOWER() adiciona overhead, especialmente em JOINs
- ‚ö†Ô∏è **Desnecess√°rio:** Comparar LOWER('n/a') √© redundante - 'n/a' √© literal
- üí° **Alternativas:**
  - Remover LOWER() se dados j√° normalizados
  - Usar collation case-insensitive: `COLLATE "C"`
  - Criar √≠ndices funcionais se LOWER() for necess√°rio

---

### 1.4 Error Handling

**SQL Server (T-SQL):**
```sql
BEGIN CATCH
    DECLARE @ErrorMessage NVARCHAR(MAX), @ErrorSeverity INT, @ErrorState INT
    SELECT @ErrorMessage = ERROR_MESSAGE() + ' Line ' + CAST(ERROR_LINE() AS NVARCHAR(5)),
           @ErrorSeverity = ERROR_SEVERITY(),
           @ErrorState = ERROR_STATE()
    ROLLBACK TRANSACTION
    RAISERROR (@ErrorMessage, @ErrorSeverity, @ErrorState)
END CATCH
```

**PostgreSQL (PL/pgSQL):**
```sql
EXCEPTION
    WHEN OTHERS THEN
        error_catch$ERROR_NUMBER := '0';
        error_catch$ERROR_SEVERITY := '0';
        error_catch$ERROR_LINE := '0';
        error_catch$ERROR_PROCEDURE := 'RECONCILEMUPSTREAM';
        GET STACKED DIAGNOSTICS 
            error_catch$ERROR_STATE = RETURNED_SQLSTATE,
            error_catch$ERROR_MESSAGE = MESSAGE_TEXT;
        
        SELECT error_catch$ERROR_MESSAGE || ' Line ' || CAST(error_catch$ERROR_LINE AS VARCHAR(5)),
               error_catch$ERROR_SEVERITY, 
               error_catch$ERROR_STATE
        INTO var_ErrorMessage, var_ErrorSeverity, var_ErrorState;
        
        ROLLBACK;
        RAISE 'Error %, severity %, state % was raised. Message: %.', 
              '50000', var_ErrorSeverity, ?, var_ErrorMessage USING ERRCODE = '50000';
```

**An√°lise:**
- ‚úÖ Estrutura geral correta (GET STACKED DIAGNOSTICS √© equivalente correto)
- ‚ùå **ERRO SINT√ÅTICO:** Placeholder `?` literal na linha do RAISE
- ‚ùå **ERRO L√ìGICO:** `'50000'` n√£o √© SQLSTATE v√°lido no PostgreSQL (deveria ser 'P0001')
- ‚ö†Ô∏è Vari√°veis de severity/state s√£o TEXT mas deveriam ser num√©ricos

---

## üö® 2. Problemas Cr√≠ticos (P0)

### 2.1 Transaction Control Broken

**Severidade:** üî¥ CRITICAL - BLOQUEIA EXECU√á√ÉO

**Problema:**
```sql
-- NO BEGIN TRANSACTION declarado

EXCEPTION
    WHEN OTHERS THEN
        ROLLBACK;  -- ‚ùå ERRO: N√£o h√° transa√ß√£o ativa para rollback!
```

**Impacto:**
- Runtime error: "ERROR: ROLLBACK can only be used in transaction blocks"
- Procedure n√£o executa em caso de erro
- Pode deixar dados em estado inconsistente

**Corre√ß√£o Recomendada:**
```sql
CREATE OR REPLACE PROCEDURE perseus_dbo.reconcilemupstream()
AS $BODY$
DECLARE
    -- declarations...
BEGIN
    -- Add explicit transaction control
    BEGIN  -- ‚Üê Transaction start
        
        -- Business logic here...
        
    EXCEPTION
        WHEN OTHERS THEN
            ROLLBACK;  -- ‚úÖ Agora tem BEGIN para fazer ROLLBACK
            -- Error handling...
            RAISE;
    END;  -- ‚Üê Transaction end
END;
$BODY$
LANGUAGE plpgsql;
```

---

### 2.2 RAISE Statement Syntax Error

**Severidade:** üî¥ CRITICAL - BLOQUEIA EXECU√á√ÉO

**Problema:**
```sql
RAISE 'Error %, severity %, state % was raised. Message: %.', 
      '50000', var_ErrorSeverity, ?, var_ErrorMessage USING ERRCODE = '50000';
      --                          ‚Üë
      --                    Literal "?" - ERRO!
```

**Impacto:**
- Syntax error durante compila√ß√£o
- Procedure n√£o pode ser criada
- Error code '50000' inv√°lido no PostgreSQL

**Corre√ß√£o Recomendada:**
```sql
-- Op√ß√£o 1: Simples e efetiva
RAISE EXCEPTION 'ReconcileMUpstream Error: % (SQLSTATE: %)', 
      var_ErrorMessage, var_ErrorState 
      USING ERRCODE = 'P0001';

-- Op√ß√£o 2: Com mais contexto
RAISE EXCEPTION 'ReconcileMUpstream Error on line %: % (State: %)', 
      error_catch$ERROR_LINE, var_ErrorMessage, var_ErrorState
      USING ERRCODE = 'P0001', 
            HINT = 'Check m_upstream_dirty_leaves table',
            DETAIL = error_catch$ERROR_PROCEDURE;
```

**Notas:**
- PostgreSQL usa SQLSTATE format: 'P0001' (5 chars)
- SQL Server error codes (50000) n√£o s√£o compat√≠veis
- Remover var_ErrorSeverity (n√£o existe equivalente direto no PostgreSQL)

---

## ‚ö†Ô∏è 3. Problemas de Alta Severidade (P1)

### 3.1 Performance: LOWER() Excessivo

**Severidade:** üü° HIGH - IMPACTO EM PERFORMANCE

**Problema:**
13 ocorr√™ncias de LOWER() desnecess√°rio:
```sql
-- Compara√ß√µes redundantes
WHERE LOWER(material_uid) != LOWER('n/a')  -- ‚ùå LOWER('n/a') √© desnecess√°rio
WHERE LOWER(dl.uid) = LOWER(mu.end_point)  -- ‚ö†Ô∏è Pode impedir uso de √≠ndices

-- Em JOINs (pior caso)
JOIN "var_dirty$aws$tmp" AS d
  ON LOWER(d.uid) = LOWER(m_upstream.start_point)  -- ‚ùå JOIN sem √≠ndice funcional
```

**Impacto:**
- Overhead de CPU em cada compara√ß√£o
- √çndices regulares n√£o podem ser usados
- Joins ficam mais lentos (nested loop scan em vez de index scan)
- Query plan menos otimizado

**An√°lise de Necessidade:**

1. **Verificar Collation do SQL Server original:**
```sql
-- No SQL Server, verificar:
SELECT SERVERPROPERTY('Collation');
-- Se retornar algo com _CI (Case Insensitive), LOWER() faz sentido
-- Se retornar _CS (Case Sensitive), LOWER() muda comportamento!
```

2. **Dados realmente t√™m case mixing?**
```sql
-- Testar no PostgreSQL:
SELECT COUNT(DISTINCT material_uid), 
       COUNT(DISTINCT LOWER(material_uid))
FROM m_upstream_dirty_leaves;
-- Se contagens s√£o iguais, LOWER() √© desnecess√°rio
```

**Corre√ß√µes Recomendadas:**

**Op√ß√£o A: Remover LOWER() (se dados normalizados)**
```sql
-- Mais r√°pido, usa √≠ndices normais
WHERE material_uid != 'n/a'
WHERE dl.uid = mu.end_point
```

**Op√ß√£o B: Usar Collation Case-Insensitive**
```sql
-- Criar collation customizada
CREATE COLLATION case_insensitive (
    provider = icu,
    locale = 'und-u-ks-level2',
    deterministic = false
);

-- Usar nas compara√ß√µes
WHERE material_uid COLLATE case_insensitive != 'n/a'
```

**Op√ß√£o C: √çndices Funcionais (se LOWER() necess√°rio)**
```sql
-- Criar √≠ndices para JOINs com LOWER()
CREATE INDEX idx_upstream_start_lower 
ON m_upstream (LOWER(start_point));

CREATE INDEX idx_upstream_end_lower 
ON m_upstream (LOWER(end_point));

CREATE INDEX idx_dirty_leaves_uid_lower
ON m_upstream_dirty_leaves (LOWER(material_uid));
```

**Recomenda√ß√£o:** Usar Op√ß√£o A se poss√≠vel (normalizar dados), seguida de Op√ß√£o C para queries que realmente precisam de case-insensitive.

---

### 3.2 Temporary Table Management Issues

**Severidade:** üü° HIGH - POTENCIAL RESOURCE LEAK

**Problema:**
```sql
-- Temporary tables s√£o criadas mas n√£o t√™m auto-cleanup
CREATE TEMPORARY TABLE oldupstream$reconcilemupstream (...);
CREATE TEMPORARY TABLE newupstream$reconcilemupstream (...);
CREATE TEMPORARY TABLE addupstream$reconcilemupstream (...);
CREATE TEMPORARY TABLE remupstream$reconcilemupstream (...);

-- Cleanup manual s√≥ acontece no EXCEPTION (pode n√£o executar)
DROP TABLE IF EXISTS oldupstream$reconcilemupstream;
DROP TABLE IF EXISTS newupstream$reconcilemupstream;
-- ...
```

**Impactos:**
1. **Session Scope:** Temp tables persistem durante toda a sess√£o PostgreSQL
2. **Memory Leak:** Se procedure falhar antes do cleanup, tables permanecem
3. **Name Collision:** Se procedure for chamada novamente, nomes podem colidir
4. **No T-SQL equivalent:** Table variables eram batch-scoped, temp tables s√£o session-scoped

**Diferen√ßas de Escopo:**

| Aspecto | SQL Server @TableVar | PostgreSQL TEMP TABLE |
|---------|----------------------|----------------------|
| **Scope** | Batch/Procedure | Session |
| **Lifetime** | Until end of batch | Until end of session OR explicit DROP |
| **Visibility** | Only in declaring scope | Entire session |
| **Auto-cleanup** | Yes (end of batch) | Only at session end |
| **Reuse in session** | ‚ùå Not possible | ‚úÖ Possible (name collision) |

**Corre√ß√µes Recomendadas:**

**Op√ß√£o A: ON COMMIT DROP (Recomendado)**
```sql
CREATE TEMPORARY TABLE old_upstream (
    start_point VARCHAR(50),
    end_point VARCHAR(50),
    path VARCHAR(500),
    level INTEGER,
    PRIMARY KEY (start_point, end_point, path)
) ON COMMIT DROP;  -- ‚úÖ Auto-cleanup no fim da transa√ß√£o
```

**Op√ß√£o B: Explicit Cleanup no In√≠cio**
```sql
-- No in√≠cio da procedure, antes de criar tables
DROP TABLE IF EXISTS old_upstream;
DROP TABLE IF EXISTS new_upstream;
DROP TABLE IF EXISTS add_upstream;
DROP TABLE IF EXISTS rem_upstream;

-- Ent√£o criar
CREATE TEMPORARY TABLE old_upstream (...);
```

**Op√ß√£o C: Use UNLOGGED Tables (se performance cr√≠tica)**
```sql
CREATE UNLOGGED TABLE tmp_old_upstream (...);
-- Mais r√°pido que temp tables, mas requer cleanup manual
-- Vis√≠vel para todas sess√µes (cuidado com concorr√™ncia!)
```

**Recomenda√ß√£o:** Usar **Op√ß√£o A (ON COMMIT DROP)** para safety + performance, ou combinar A + B para m√°xima robustez.

---

## ‚ö†Ô∏è 4. Problemas de M√©dia Severidade (P2)

### 4.1 Nomenclatura Confusa

**Problema:**
```sql
CREATE TEMPORARY TABLE oldupstream$reconcilemupstream (...)
CREATE TEMPORARY TABLE newupstream$reconcilemupstream (...)
CREATE TEMPORARY TABLE addupstream$reconcilemupstream (...)
CREATE TEMPORARY TABLE remupstream$reconcilemupstream (...)
```

**Impacto:**
- Dificulta leitura e manuten√ß√£o
- Nome muito longo para queries
- Padr√£o `$` n√£o √© comum em PostgreSQL (mais comum underscore `_`)

**Corre√ß√£o Recomendada:**
```sql
CREATE TEMPORARY TABLE old_upstream (...) ON COMMIT DROP;
CREATE TEMPORARY TABLE new_upstream (...) ON COMMIT DROP;
CREATE TEMPORARY TABLE add_upstream (...) ON COMMIT DROP;
CREATE TEMPORARY TABLE rem_upstream (...) ON COMMIT DROP;
```

---

### 4.2 Depend√™ncia Externa N√£o Validada

**Problema:**
```sql
-- Chamada para fun√ß√£o que pode n√£o existir
PERFORM perseus_dbo.goolist$aws$f('"var_dirty$aws$tmp"');
```

**An√°lise:**
- Nome estranho com `$` no meio
- N√£o sabemos se essa fun√ß√£o existe no PostgreSQL
- Parece ser uma inicializa√ß√£o de temp table list
- AWS SCT pode ter criado essa fun√ß√£o ou pode estar faltando

**Verifica√ß√£o Necess√°ria:**
```sql
-- Verificar se fun√ß√£o existe
SELECT proname, prosrc 
FROM pg_proc 
WHERE proname = 'goolist$aws$f';

-- Se n√£o existir, investigar o que ela fazia no SQL Server
```

**Impacto:**
- Se fun√ß√£o n√£o existir: Runtime error
- Se fun√ß√£o tiver comportamento diferente: L√≥gica quebrada

---

### 4.3 Falta de Logging/Observabilidade

**Problema:**
- Nenhum logging de execu√ß√£o
- N√£o h√° visibilidade de quantos registros foram processados
- Dificulta troubleshooting

**Corre√ß√£o Recomendada:**
```sql
-- Adicionar logging
RAISE NOTICE 'ReconcileMUpstream: Processing % dirty materials', var_dirty_count;
RAISE NOTICE 'ReconcileMUpstream: Adding % rows, removing % rows', 
             var_add_rows, var_rem_rows;

-- Ou usar pg_stat_statements para tracking
-- Ou inserir em audit table
```

---

## üìä 5. An√°lise de Coment√°rios AWS SCT

### 5.1 C√≥digo [7659] - Severity LOW (4 ocorr√™ncias)

**Mensagem:**
> "If you use recursion, make sure that table variables in your source database and temporary tables in your target database have the same scope."

**An√°lise:**
- ‚ö†Ô∏è **Classificado como LOW, mas √© IMPORTANTE**
- Diferen√ßa fundamental de comportamento:
  - T-SQL table variables: batch-scoped (auto-cleanup)
  - PostgreSQL temp tables: session-scoped (manual cleanup)
- **Risco:** Memory leaks se procedure falhar

**Recomenda√ß√£o:**
- N√£o ignorar esse warning
- Implementar cleanup adequado (ON COMMIT DROP)
- Testar comportamento em cen√°rios de erro

---

### 5.2 C√≥digo [7807] - Severity CRITICAL

**Mensagem:**
> "PostgreSQL does not support explicit transaction management commands such as BEGIN TRAN, SAVE TRAN in functions. Convert your source code manually."

**An√°lise:**
- ‚úÖ **Corretamente classificado como CRITICAL**
- AWS SCT identificou o problema mas n√£o corrigiu
- **Confus√£o:** PostgreSQL FUNCTIONS n√£o suportam transaction control, mas PROCEDURES suportam
- SCT converteu para PROCEDURE, ent√£o transaction control DEVERIA funcionar

**Solu√ß√£o:**
- Adicionar transaction control expl√≠cito
- A convers√£o para PROCEDURE foi correta
- Apenas faltou adicionar BEGIN/END do transaction block

---

### 5.3 C√≥digo [7795] - Severity LOW (13 ocorr√™ncias)

**Mensagem:**
> "In PostgreSQL, string operations are case sensitive. Review the converted code to make sure that it compares strings correctly."

**An√°lise:**
- ‚ö†Ô∏è **Abordagem conservadora:** SCT assumiu case-insensitive e adicionou LOWER()
- **Trade-off:**
  - ‚úÖ Preserva comportamento se SQL Server era case-insensitive
  - ‚ùå Adiciona overhead desnecess√°rio se dados s√£o normalizados
  - ‚ùå Pode mudar comportamento se SQL Server era case-sensitive

**Recomenda√ß√£o:**
- Verificar collation do SQL Server original
- Testar se dados realmente t√™m case mixing
- Remover LOWER() se poss√≠vel ou criar √≠ndices funcionais

---

### 5.4 C√≥digo [7922] - Severity LOW

**Mensagem:**
> "PostgreSQL uses a different approach to handle errors compared to the source code. Review the converted code and change it where necessary."

**An√°lise:**
- ‚úÖ Warning informativo correto
- GET STACKED DIAGNOSTICS √© equivalente adequado
- Problema n√£o est√° na convers√£o da estrutura, mas no RAISE statement

---

### 5.5 C√≥digo [7615] - Severity CRITICAL

**Mensagem:**
> "Your code ends a transaction inside a block with exception handlers. Revise your code to move transaction control to the application side and try again."

**An√°lise:**
- ‚ö†Ô∏è **Warning controverso:**
  - SCT sugere mover transaction para application
  - Mas PostgreSQL PROCEDURES suportam transaction control
  - √â v√°lido ter COMMIT/ROLLBACK dentro de procedure
- **Raz√£o do warning:** Provavelmente porque FUNCTIONS n√£o suportam
- **Confus√£o:** SCT converteu para PROCEDURE mas deu warning de FUNCTION

**Solu√ß√£o:**
- Ignorar sugest√£o de mover para application
- Manter transaction control na procedure (√© suportado)
- Apenas corrigir a implementa√ß√£o (adicionar BEGIN/END adequados)

---

## üí° 6. Recomenda√ß√µes de Corre√ß√£o

### 6.1 P0 - CR√çTICO (Must Fix Before Production)

#### Fix #1: Transaction Control
```sql
CREATE OR REPLACE PROCEDURE perseus_dbo.reconcilemupstream()
AS $BODY$
DECLARE
    var_add_rows INTEGER;
    var_rem_rows INTEGER;
    var_dirty_count INTEGER;
    var_ErrorMessage TEXT;
    var_ErrorSeverity INTEGER;
    var_ErrorState INTEGER;
BEGIN
    -- Temporary tables with auto-cleanup
    CREATE TEMPORARY TABLE old_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    -- ... other temp tables ...
    
    -- Initialize external function
    PERFORM perseus_dbo.goolist$aws$f('"var_dirty$aws$tmp"');
    
    -- Start transaction block for exception handling
    BEGIN  -- ‚Üê FIX: Add transaction block
        
        -- ============================================
        -- BUSINESS LOGIC HERE
        -- ============================================
        INSERT INTO "var_dirty$aws$tmp"
        SELECT DISTINCT material_uid AS uid 
        FROM perseus_dbo.m_upstream_dirty_leaves
        WHERE material_uid != 'n/a'  -- Removed unnecessary LOWER()
        LIMIT 10;
        
        -- ... rest of business logic ...
        
        IF var_add_rows > 0 THEN
            INSERT INTO perseus_dbo.m_upstream (start_point, end_point, path, level)
            SELECT start_point, end_point, path, level FROM add_upstream;
        END IF;
        
        IF var_rem_rows > 0 THEN
            DELETE FROM perseus_dbo.m_upstream
            WHERE start_point IN (SELECT uid FROM "var_dirty$aws$tmp")
              AND NOT EXISTS (
                  SELECT 1 FROM new_upstream f
                  WHERE f.start_point = m_upstream.start_point
                    AND f.end_point = m_upstream.end_point
                    AND f.path = m_upstream.path
              );
        END IF;
        
        -- ============================================
        -- END BUSINESS LOGIC
        -- ============================================
        
    EXCEPTION
        WHEN OTHERS THEN
            -- Now ROLLBACK will work correctly
            ROLLBACK;
            
            -- Get error details
            GET STACKED DIAGNOSTICS 
                var_ErrorState = RETURNED_SQLSTATE,
                var_ErrorMessage = MESSAGE_TEXT;
            
            -- FIX: Corrected RAISE statement
            RAISE EXCEPTION 'ReconcileMUpstream failed: % (SQLSTATE: %)', 
                  var_ErrorMessage, var_ErrorState
                  USING ERRCODE = 'P0001',
                        HINT = 'Check m_upstream and m_upstream_dirty_leaves tables';
            
    END;  -- ‚Üê FIX: Close transaction block
    
END;
$BODY$
LANGUAGE plpgsql;
```

**Mudan√ßas Cr√≠ticas:**
1. ‚úÖ Adicionado `BEGIN...END` block para transaction control
2. ‚úÖ ROLLBACK agora tem transaction ativa
3. ‚úÖ Temp tables com `ON COMMIT DROP`
4. ‚úÖ Corrigido RAISE statement (sem `?`, SQLSTATE v√°lido)
5. ‚úÖ Removido LOWER() desnecess√°rio

---

#### Fix #2: RAISE Statement Correto
```sql
-- ‚ùå ERRADO (AWS SCT):
RAISE 'Error %, severity %, state % was raised. Message: %.', 
      '50000', var_ErrorSeverity, ?, var_ErrorMessage USING ERRCODE = '50000';

-- ‚úÖ CORRETO:
RAISE EXCEPTION 'ReconcileMUpstream Error: % (State: %)', 
      var_ErrorMessage, var_ErrorState
      USING ERRCODE = 'P0001',
            HINT = 'Check procedure logic and input data',
            DETAIL = 'Procedure: RECONCILEMUPSTREAM';
```

**Por que funciona:**
- `EXCEPTION` √© o n√≠vel correto para errors (vs NOTICE, WARNING, INFO)
- `P0001` √© SQLSTATE v√°lido do PostgreSQL para user-defined exception
- Removido `?` literal que causava syntax error
- Removido `var_ErrorSeverity` (n√£o tem equivalente direto no PostgreSQL)
- Adicionado HINT e DETAIL para melhor debugging

---

### 6.2 P1 - ALTO (Should Fix)

#### Optimization #1: Remove Unnecessary LOWER()

**Antes (AWS SCT):**
```sql
-- 13 ocorr√™ncias como esta:
WHERE LOWER(material_uid) != LOWER('n/a')
WHERE LOWER(dl.uid) = LOWER(mu.end_point)
JOIN @dirty d ON LOWER(d.uid) = LOWER(m_upstream.start_point)
```

**Depois (Otimizado):**
```sql
-- Se dados s√£o normalizados (case-consistent):
WHERE material_uid != 'n/a'
WHERE dl.uid = mu.end_point
JOIN "var_dirty$aws$tmp" d ON d.uid = m_upstream.start_point
```

**Como Validar:**
```sql
-- 1. Verificar se dados t√™m case mixing
SELECT 
    COUNT(*) as total_rows,
    COUNT(DISTINCT material_uid) as unique_original,
    COUNT(DISTINCT LOWER(material_uid)) as unique_lowercase
FROM perseus_dbo.m_upstream_dirty_leaves;

-- Se unique_original = unique_lowercase, LOWER() √© desnecess√°rio

-- 2. Verificar collation do banco
SELECT datcollate FROM pg_database WHERE datname = current_database();

-- 3. Testar performance
EXPLAIN ANALYZE
SELECT * FROM m_upstream 
WHERE material_uid = 'M12345';  -- Com √≠ndice

EXPLAIN ANALYZE
SELECT * FROM m_upstream 
WHERE LOWER(material_uid) = LOWER('M12345');  -- Sem √≠ndice (seq scan)
```

**Se LOWER() for necess√°rio, criar √≠ndices:**
```sql
-- √çndices funcionais para queries com LOWER()
CREATE INDEX idx_upstream_start_lower 
ON perseus_dbo.m_upstream (LOWER(start_point));

CREATE INDEX idx_upstream_end_lower 
ON perseus_dbo.m_upstream (LOWER(end_point));

CREATE INDEX idx_dirty_leaves_uid_lower
ON perseus_dbo.m_upstream_dirty_leaves (LOWER(material_uid));

-- Verificar uso do √≠ndice
EXPLAIN ANALYZE
SELECT * FROM m_upstream 
WHERE LOWER(start_point) = 'value';
-- Deve usar: Index Scan using idx_upstream_start_lower
```

---

#### Optimization #2: Improved Temp Table Management

```sql
-- Melhor abordagem: combinar auto-cleanup + defensive cleanup
CREATE OR REPLACE PROCEDURE perseus_dbo.reconcilemupstream()
AS $BODY$
DECLARE
    -- declarations...
BEGIN
    -- DEFENSIVE: Drop any leftover tables from failed previous runs
    DROP TABLE IF EXISTS old_upstream;
    DROP TABLE IF EXISTS new_upstream;
    DROP TABLE IF EXISTS add_upstream;
    DROP TABLE IF EXISTS rem_upstream;
    
    -- Create with auto-cleanup
    CREATE TEMPORARY TABLE old_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    CREATE TEMPORARY TABLE new_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    CREATE TEMPORARY TABLE add_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    CREATE TEMPORARY TABLE rem_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    -- Initialize external function
    PERFORM perseus_dbo.goolist$aws$f('"var_dirty$aws$tmp"');
    
    BEGIN  -- Transaction block
        -- Business logic...
    EXCEPTION
        WHEN OTHERS THEN
            -- Error handling...
            -- Note: ON COMMIT DROP will auto-cleanup even on error
    END;
    
END;
$BODY$
LANGUAGE plpgsql;
```

**Benef√≠cios:**
1. ‚úÖ `DROP TABLE IF EXISTS` no in√≠cio: previne erros de tables j√° existentes
2. ‚úÖ `ON COMMIT DROP`: auto-cleanup ao fim da transa√ß√£o
3. ‚úÖ Funciona mesmo com ROLLBACK (tables s√£o dropadas no commit/rollback)
4. ‚úÖ Previne memory leaks
5. ‚úÖ Nomes limpos e leg√≠veis

---

### 6.3 P2 - M√âDIO (Good to Have)

#### Enhancement #1: Add Logging/Observability

```sql
-- No in√≠cio da procedure
RAISE NOTICE 'ReconcileMUpstream: Starting reconciliation process';

-- Ap√≥s contar dirty records
RAISE NOTICE 'ReconcileMUpstream: Found % dirty materials to process', var_dirty_count;

-- Ap√≥s calcular deltas
RAISE NOTICE 'ReconcileMUpstream: Delta - Adding % rows, Removing % rows', 
             var_add_rows, var_rem_rows;

-- No fim (sucesso)
RAISE NOTICE 'ReconcileMUpstream: Completed successfully';

-- No EXCEPTION (erro)
RAISE WARNING 'ReconcileMUpstream: Failed with error: % (State: %)', 
              var_ErrorMessage, var_ErrorState;
```

**Ou usar tabela de audit:**
```sql
-- Criar tabela de audit
CREATE TABLE IF NOT EXISTS perseus_dbo.procedure_audit_log (
    log_id SERIAL PRIMARY KEY,
    procedure_name VARCHAR(100),
    execution_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    status VARCHAR(20),  -- 'SUCCESS', 'FAILED'
    rows_affected INTEGER,
    error_message TEXT,
    execution_time_ms INTEGER
);

-- No in√≠cio da procedure
DECLARE
    v_start_time TIMESTAMP;
    v_end_time TIMESTAMP;
    v_execution_time INTEGER;
BEGIN
    v_start_time := clock_timestamp();
    
    -- Business logic...
    
    v_end_time := clock_timestamp();
    v_execution_time := EXTRACT(MILLISECONDS FROM (v_end_time - v_start_time));
    
    -- Log sucesso
    INSERT INTO perseus_dbo.procedure_audit_log 
        (procedure_name, status, rows_affected, execution_time_ms)
    VALUES 
        ('ReconcileMUpstream', 'SUCCESS', var_add_rows + var_rem_rows, v_execution_time);
    
EXCEPTION
    WHEN OTHERS THEN
        -- Log erro
        INSERT INTO perseus_dbo.procedure_audit_log 
            (procedure_name, status, error_message)
        VALUES 
            ('ReconcileMUpstream', 'FAILED', var_ErrorMessage);
        RAISE;
END;
```

---

#### Enhancement #2: Validate External Dependencies

```sql
-- No in√≠cio da procedure, validar se depend√™ncias existem
DO $$
BEGIN
    -- Verificar se fun√ß√£o goolist$aws$f existe
    IF NOT EXISTS (
        SELECT 1 FROM pg_proc 
        WHERE proname = 'goolist$aws$f' 
          AND pronamespace = 'perseus_dbo'::regnamespace
    ) THEN
        RAISE EXCEPTION 'Dependency missing: perseus_dbo.goolist$aws$f function not found'
              USING HINT = 'Ensure all dependencies are deployed before running this procedure';
    END IF;
    
    -- Verificar se tabelas existem
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.tables 
        WHERE table_schema = 'perseus_dbo' 
          AND table_name = 'm_upstream'
    ) THEN
        RAISE EXCEPTION 'Table missing: perseus_dbo.m_upstream'
              USING HINT = 'Ensure database schema is fully deployed';
    END IF;
    
    -- Verificar se view existe (se McGetUpStreamByList √© uma view)
    -- ...
END $$;
```

---

#### Enhancement #3: Performance Indexes

```sql
-- Se LOWER() for mantido, criar √≠ndices funcionais
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_upstream_start_lower 
ON perseus_dbo.m_upstream (LOWER(start_point))
WHERE start_point IS NOT NULL;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_upstream_end_lower 
ON perseus_dbo.m_upstream (LOWER(end_point))
WHERE end_point IS NOT NULL;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_dirty_leaves_uid_lower
ON perseus_dbo.m_upstream_dirty_leaves (LOWER(material_uid))
WHERE material_uid IS NOT NULL;

-- √çndices adicionais para performance (sem LOWER)
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_upstream_composite
ON perseus_dbo.m_upstream (start_point, end_point, path);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_dirty_leaves_uid
ON perseus_dbo.m_upstream_dirty_leaves (material_uid)
WHERE material_uid != 'n/a';

-- Analisar tabelas ap√≥s criar √≠ndices
ANALYZE perseus_dbo.m_upstream;
ANALYZE perseus_dbo.m_upstream_dirty_leaves;
```

**Uso de CONCURRENTLY:**
- ‚úÖ Permite criar √≠ndices sem lock da tabela
- ‚úÖ Produ√ß√£o pode continuar operando
- ‚ö†Ô∏è Mais lento que CREATE INDEX normal
- ‚ö†Ô∏è Pode falhar se houver transa√ß√µes longas

---

## üìà 7. An√°lise de Performance

### 7.1 Query Plan Analysis (Hipot√©tico)

**Scenario: Query com LOWER() vs sem LOWER()**

```sql
-- Query 1: COM LOWER() (AWS SCT gerou assim)
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM perseus_dbo.m_upstream
WHERE LOWER(start_point) = LOWER('M12345');

-- Expected Plan:
-- Seq Scan on m_upstream  (cost=0.00..1500.00 rows=100 width=200)
--   Filter: (lower(start_point) = 'm12345'::text)
--   Rows Removed by Filter: 10000
-- Planning Time: 0.5 ms
-- Execution Time: 45.2 ms

-- Query 2: SEM LOWER() (otimizado)
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM perseus_dbo.m_upstream
WHERE start_point = 'M12345';

-- Expected Plan (com √≠ndice):
-- Index Scan using idx_upstream_start on m_upstream (cost=0.29..8.31 rows=1 width=200)
--   Index Cond: (start_point = 'M12345'::text)
-- Planning Time: 0.3 ms
-- Execution Time: 0.8 ms

-- GANHO: 98.2% mais r√°pido (45ms ‚Üí 0.8ms)
```

### 7.2 Performance Estimates

| Opera√ß√£o | Com LOWER() | Sem LOWER() | Ganho |
|----------|-------------|-------------|-------|
| **Single row lookup** | 45ms (seq scan) | 0.8ms (index scan) | 98.2% |
| **JOIN em 10K rows** | 2500ms (nested loop) | 150ms (index join) | 94.0% |
| **Compara√ß√£o string** | ~0.05ms/row | ~0.001ms/row | 98.0% |

**Impacto na procedure ReconcileMUpstream:**
- 13 queries com LOWER()
- Assumindo 1000 rows processados
- **Overhead estimado:** 13 √ó 1000 √ó 0.049ms = ~637ms extra

---

### 7.3 Memory Usage

**T-SQL Table Variables:**
- In-memory (tempdb)
- Batch-scoped (auto-cleanup)
- Typical size: few KB to few MB

**PostgreSQL Temp Tables:**
- Disk-backed (can spill to disk)
- Session-scoped (manual cleanup)
- **Risk:** 4 temp tables √ó session lifetime = memory leak

**Recomenda√ß√£o:**
- Use ON COMMIT DROP
- Monitor temp table usage: `SELECT * FROM pg_stat_user_tables WHERE schemaname = 'pg_temp_*'`

---

## üîê 8. An√°lise de Seguran√ßa

### 8.1 Inje√ß√£o SQL

**Status:** ‚úÖ SEGURO

**An√°lise:**
- Nenhum dynamic SQL detectado
- Todos os valores s√£o parametrizados
- Nenhum concatena√ß√£o de strings em queries

**Exemplo seguro (mantido):**
```sql
-- Seguro: usa placeholder correto
INSERT INTO "var_dirty$aws$tmp"
SELECT DISTINCT material_uid AS uid 
FROM perseus_dbo.m_upstream_dirty_leaves
WHERE material_uid != 'n/a'
LIMIT 10;
```

---

### 8.2 Error Handling & Data Integrity

**Status:** ‚ö†Ô∏è PRECISA CORRE√á√ÉO

**Problemas:**
1. ‚ùå ROLLBACK sem transaction ativa (corrigido na se√ß√£o 6.1)
2. ‚ö†Ô∏è N√£o h√° valida√ß√£o de dados de entrada
3. ‚ö†Ô∏è N√£o h√° check de permiss√µes

**Recomenda√ß√µes:**
```sql
-- Adicionar valida√ß√£o de dados
IF NOT EXISTS (
    SELECT 1 FROM information_schema.tables 
    WHERE table_schema = 'perseus_dbo' 
      AND table_name = 'm_upstream'
) THEN
    RAISE EXCEPTION 'Table m_upstream does not exist'
          USING ERRCODE = 'P0001',
                HINT = 'Check database schema';
END IF;

-- Adicionar check de permiss√µes
IF NOT has_table_privilege('perseus_dbo.m_upstream', 'INSERT, DELETE') THEN
    RAISE EXCEPTION 'Insufficient privileges to modify m_upstream'
          USING ERRCODE = '42501';  -- insufficient_privilege
END IF;
```

---

### 8.3 Audit Trail

**Status:** ‚ùå FALTANDO

**Recomenda√ß√£o:** Adicionar audit logging (veja se√ß√£o 6.3 Enhancement #1)

---

## üìä 9. Scorecard Detalhado

### 9.1 Categorias de Avalia√ß√£o

#### Corre√ß√£o L√≥gica: 7/10 ‚úÖ
**Pontos Positivos:**
- ‚úÖ Fluxo de dados preservado
- ‚úÖ L√≥gica de neg√≥cio mantida
- ‚úÖ Estrutura de dados correta

**Pontos Negativos:**
- ‚ùå Transaction control quebrado (-2 pontos)
- ‚ùå RAISE statement com erro (-1 ponto)

---

#### Corre√ß√£o Sint√°tica: 5/10 ‚ö†Ô∏è
**Pontos Positivos:**
- ‚úÖ Maioria da sintaxe convertida corretamente
- ‚úÖ Convers√£o de tipos adequada
- ‚úÖ Estrutura de procedure correta

**Pontos Negativos:**
- ‚ùå Literal `?` no RAISE (-2 pontos)
- ‚ùå ROLLBACK sem BEGIN (-2 pontos)
- ‚ö†Ô∏è Nomenclatura estranha (-1 ponto)

---

#### Performance: 6/10 ‚ö†Ô∏è
**Pontos Positivos:**
- ‚úÖ Estrutura geral eficiente
- ‚úÖ Uso de temp tables (similar a table variables)
- ‚úÖ Primary keys nas temp tables

**Pontos Negativos:**
- ‚ùå 13√ó LOWER() desnecess√°rio (-3 pontos)
- ‚ö†Ô∏è Falta de √≠ndices funcionais se LOWER() mantido (-1 ponto)

---

#### Manutenibilidade: 7/10 ‚úÖ
**Pontos Positivos:**
- ‚úÖ Coment√°rios originais preservados (+2 pontos)
- ‚úÖ Coment√°rios AWS SCT √∫teis (+1 ponto)
- ‚úÖ Estrutura leg√≠vel (+1 ponto)

**Pontos Negativos:**
- ‚ö†Ô∏è Nomenclatura confusa (-2 pontos)
- ‚ö†Ô∏è Falta de logging (-1 ponto)

---

#### Seguran√ßa: 8/10 ‚úÖ
**Pontos Positivos:**
- ‚úÖ Sem SQL injection (+3 pontos)
- ‚úÖ Error handling existe (+2 pontos)
- ‚úÖ ROLLBACK para data integrity (+1 ponto)

**Pontos Negativos:**
- ‚ö†Ô∏è Error handling quebrado (-1 ponto)
- ‚ö†Ô∏è Falta audit trail (-1 ponto)

---

### 9.2 Score Final: 6.6/10 (66%)

**Breakdown:**
- Corre√ß√£o L√≥gica: 7/10 √ó 30% = 2.1
- Corre√ß√£o Sint√°tica: 5/10 √ó 25% = 1.25
- Performance: 6/10 √ó 20% = 1.2
- Manutenibilidade: 7/10 √ó 15% = 1.05
- Seguran√ßa: 8/10 √ó 10% = 0.8

**Total: 6.4/10 = 64%**

---

## üéØ 10. Plano de A√ß√£o

### 10.1 Roadmap de Corre√ß√£o

**FASE 1: Cr√≠tico (Bloqueia Deploy) - 2-4 horas**
- [ ] Corrigir transaction control (adicionar BEGIN...END)
- [ ] Corrigir RAISE statement (remover ?, usar SQLSTATE correto)
- [ ] Testar procedure em ambiente de dev
- [ ] Validar que n√£o h√° syntax errors

**FASE 2: Alto Impacto (Performance) - 4-8 horas**
- [ ] Analisar necessidade de LOWER()
- [ ] Remover LOWER() desnecess√°rio
- [ ] Criar √≠ndices funcionais se LOWER() for mantido
- [ ] Testar performance com EXPLAIN ANALYZE
- [ ] Adicionar ON COMMIT DROP nas temp tables

**FASE 3: Melhorias (Production-Ready) - 4-6 horas**
- [ ] Adicionar logging/observability
- [ ] Renomear temp tables (nomes limpos)
- [ ] Validar depend√™ncias externas
- [ ] Adicionar audit trail
- [ ] Documentar mudan√ßas

**FASE 4: Valida√ß√£o Final - 2-3 horas**
- [ ] Testes unit√°rios
- [ ] Testes de integra√ß√£o
- [ ] Testes de carga (performance)
- [ ] Code review
- [ ] Deploy em staging

**TEMPO TOTAL ESTIMADO: 12-21 horas**

---

### 10.2 Checklist de Valida√ß√£o

**Antes de Deploy:**
- [ ] Procedure compila sem erros
- [ ] Todos os testes passam
- [ ] Performance √© aceit√°vel (< 2√ó tempo do SQL Server)
- [ ] Nenhum warning cr√≠tico do PostgreSQL
- [ ] Logging est√° funcionando
- [ ] Rollback funciona corretamente
- [ ] Temp tables s√£o cleanup corretamente
- [ ] Depend√™ncias externas foram validadas

**Ap√≥s Deploy (Monitoring):**
- [ ] Monitorar logs de erro
- [ ] Monitorar performance (execution time)
- [ ] Monitorar uso de mem√≥ria (temp tables)
- [ ] Validar que n√£o h√° locks longos
- [ ] Verificar audit logs

---

## üìù 11. Conclus√µes

### 11.1 Qualidade da Ferramenta AWS SCT

**Pontos Fortes:**
- ‚úÖ Converte ~70% do c√≥digo corretamente
- ‚úÖ Identifica problemas cr√≠ticos com warnings
- ‚úÖ Preserva coment√°rios originais
- ‚úÖ Bom ponto de partida para convers√µes

**Pontos Fracos:**
- ‚ùå N√£o corrige problemas que identifica
- ‚ùå Adiciona overhead desnecess√°rio (LOWER())
- ‚ùå Nomenclatura confusa ($ nos nomes)
- ‚ùå N√£o finaliza transaction control adequadamente

**Compara√ß√£o com Convers√£o Manual:**
- AWS SCT: 70% do trabalho, 30% precisa revis√£o
- Manual: 100% do trabalho, mas muito mais lento

**Recomenda√ß√£o:** Use AWS SCT como **ponto de partida**, mas **sempre revise manualmente** antes de produ√ß√£o.

---

### 11.2 Li√ß√µes Aprendidas

**Para Futuras Convers√µes:**

1. **Sempre revisar warnings CRITICAL** mesmo que c√≥digo compile
2. **Testar transaction control** em todos os caminhos (happy path + exceptions)
3. **Analisar necessidade de LOWER()** antes de aceitar
4. **Validar SQLSTATE codes** - SQL Server e PostgreSQL s√£o diferentes
5. **Adicionar logging desde o in√≠cio** para facilitar troubleshooting

---

### 11.3 Pr√≥ximos Passos

**Recomenda√ß√µes para Pierre:**

1. **Aplicar corre√ß√µes P0** imediatamente (se√ß√£o 6.1)
2. **Testar em ambiente de dev** com dados reais
3. **Avaliar performance** com e sem LOWER()
4. **Implementar melhorias P1/P2** se tempo permitir
5. **Documentar mudan√ßas** para equipe

**Se m√∫ltiplas procedures:**
- Criar template de corre√ß√£o baseado nesta an√°lise
- Automatizar partes repetitivas (ex: renomea√ß√£o de tables)
- Priorizar procedures cr√≠ticas primeiro

---

## üìö 12. Refer√™ncias

### PostgreSQL Documentation
- [PL/pgSQL Error Handling](https://www.postgresql.org/docs/current/plpgsql-control-structures.html#PLPGSQL-ERROR-TRAPPING)
- [Transaction Management in Procedures](https://www.postgresql.org/docs/current/plpgsql-transactions.html)
- [Temporary Tables](https://www.postgresql.org/docs/current/sql-createtable.html)
- [RAISE Statement](https://www.postgresql.org/docs/current/plpgsql-errors-and-messages.html)
- [SQLSTATE Codes](https://www.postgresql.org/docs/current/errcodes-appendix.html)

### SQL Server Migration
- [AWS SCT User Guide](https://docs.aws.amazon.com/SchemaConversionTool/latest/userguide/CHAP_Welcome.html)
- [T-SQL to PL/pgSQL Conversion Patterns](https://wiki.postgresql.org/wiki/Oracle_to_Postgres_Conversion)

### Performance
- [PostgreSQL Query Performance](https://www.postgresql.org/docs/current/performance-tips.html)
- [Functional Indexes](https://www.postgresql.org/docs/current/indexes-expressional.html)

---

## üìä 13. Anexo: C√≥digo Corrigido Completo

```sql
-- ===================================================================
-- CORRECTED VERSION: ReconcileMUpstream
-- ===================================================================
-- Original: SQL Server T-SQL
-- Converted by: AWS Schema Conversion Tool
-- Reviewed & Fixed by: Pierre Ribeiro (2025-11-12)
-- 
-- CHANGES:
-- 1. Fixed transaction control (added BEGIN/END block)
-- 2. Fixed RAISE statement (removed '?', correct SQLSTATE)
-- 3. Optimized LOWER() usage (removed unnecessary calls)
-- 4. Added ON COMMIT DROP for temp tables
-- 5. Improved temp table naming
-- 6. Added logging/observability
-- 7. Added validation for external dependencies
-- ===================================================================

CREATE OR REPLACE PROCEDURE perseus_dbo.reconcilemupstream()
AS $BODY$
DECLARE
    var_add_rows INTEGER;
    var_rem_rows INTEGER;
    var_dirty_count INTEGER;
    var_ErrorMessage TEXT;
    var_ErrorState TEXT;
    var_start_time TIMESTAMP;
    var_end_time TIMESTAMP;
    var_execution_time INTEGER;
BEGIN
    var_start_time := clock_timestamp();
    
    RAISE NOTICE 'ReconcileMUpstream: Starting reconciliation process';
    
    -- ===================================================================
    -- DEFENSIVE CLEANUP: Drop any leftover tables from failed runs
    -- ===================================================================
    DROP TABLE IF EXISTS old_upstream;
    DROP TABLE IF EXISTS new_upstream;
    DROP TABLE IF EXISTS add_upstream;
    DROP TABLE IF EXISTS rem_upstream;
    
    -- ===================================================================
    -- CREATE TEMPORARY TABLES WITH AUTO-CLEANUP
    -- ===================================================================
    CREATE TEMPORARY TABLE old_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    CREATE TEMPORARY TABLE new_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    CREATE TEMPORARY TABLE add_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    CREATE TEMPORARY TABLE rem_upstream (
        start_point VARCHAR(50),
        end_point VARCHAR(50),
        path VARCHAR(500),
        level INTEGER,
        PRIMARY KEY (start_point, end_point, path)
    ) ON COMMIT DROP;
    
    -- ===================================================================
    -- INITIALIZE EXTERNAL FUNCTION
    -- Note: This function prepares the var_dirty$aws$tmp table
    -- Original comment from dolan (2015-08-07):
    -- "not sure where declared, but it's what McGetUpStreamByList expects
    --  embedding the recursive query, or a call directory to the view upstream
    --  from within the proc doesn't work, for reasons are presently unclear to me"
    -- ===================================================================
    PERFORM perseus_dbo.goolist$aws$f('"var_dirty$aws$tmp"');
    
    -- ===================================================================
    -- TRANSACTION BLOCK WITH EXCEPTION HANDLING
    -- ===================================================================
    BEGIN
        
        -- ===============================================================
        -- STEP 1: Get dirty materials (up to 10 at a time)
        -- ===============================================================
        INSERT INTO "var_dirty$aws$tmp"
        SELECT DISTINCT material_uid AS uid
        FROM perseus_dbo.m_upstream_dirty_leaves
        WHERE material_uid != 'n/a'  -- Removed LOWER() - assuming normalized data
        LIMIT 10;
        
        -- ===============================================================
        -- STEP 2: Expand to include start_points that connect to dirty materials
        -- ===============================================================
        INSERT INTO "var_dirty$aws$tmp"
        SELECT DISTINCT start_point AS uid
        FROM perseus_dbo.m_upstream AS mu
        WHERE EXISTS (
            SELECT 1 
            FROM "var_dirty$aws$tmp" AS dl 
            WHERE dl.uid = mu.end_point  -- Removed LOWER() if data is normalized
        )
        AND NOT EXISTS (
            SELECT 1 
            FROM "var_dirty$aws$tmp" AS dl1 
            WHERE dl1.uid = mu.start_point
        )
        AND start_point != 'n/a';
        
        -- ===============================================================
        -- STEP 3: Count dirty materials to process
        -- ===============================================================
        SELECT COUNT(*)
        INTO var_dirty_count
        FROM "var_dirty$aws$tmp";
        
        RAISE NOTICE 'ReconcileMUpstream: Found % dirty materials to process', var_dirty_count;
        
        -- ===============================================================
        -- PROCESS DIRTY MATERIALS IF ANY FOUND
        -- ===============================================================
        IF var_dirty_count > 0 THEN
            
            -- ===========================================================
            -- STEP 4: Delete processed materials from dirty_leaves table
            -- ===========================================================
            DELETE FROM perseus_dbo.m_upstream_dirty_leaves
            WHERE EXISTS (
                SELECT 1 
                FROM "var_dirty$aws$tmp" AS d
                WHERE d.uid = m_upstream_dirty_leaves.material_uid
            );
            
            -- ===========================================================
            -- STEP 5: Capture OLD state of upstream
            -- ===========================================================
            INSERT INTO old_upstream (start_point, end_point, path, level)
            SELECT start_point, end_point, path, level
            FROM perseus_dbo.m_upstream
            JOIN "var_dirty$aws$tmp" AS d
                ON d.uid = m_upstream.start_point;
            
            -- ===========================================================
            -- STEP 6: Calculate NEW state of upstream
            -- ===========================================================
            INSERT INTO new_upstream
            SELECT start_point, end_point, path, level
            FROM perseus_dbo.mcgetupstreambylist("var_dirty$aws$tmp");
            
            -- ===========================================================
            -- STEP 7: Determine rows to ADD (in NEW but not in OLD)
            -- ===========================================================
            INSERT INTO add_upstream (start_point, end_point, path, level)
            SELECT start_point, end_point, path, level
            FROM new_upstream AS n
            WHERE NOT EXISTS (
                SELECT 1 
                FROM old_upstream AS o
                WHERE o.start_point = n.start_point
                  AND o.end_point = n.end_point
                  AND o.path = n.path
            );
            
            -- ===========================================================
            -- STEP 8: Determine rows to REMOVE (in OLD but not in NEW)
            -- ===========================================================
            INSERT INTO rem_upstream (start_point, end_point, path, level)
            SELECT start_point, end_point, path, level
            FROM old_upstream AS o
            WHERE NOT EXISTS (
                SELECT 1 
                FROM new_upstream AS n
                WHERE n.start_point = o.start_point
                  AND n.end_point = o.end_point
                  AND n.path = o.path
            );
            
            -- ===========================================================
            -- STEP 9: Count changes to apply
            -- ===========================================================
            SELECT COUNT(*) INTO var_add_rows FROM add_upstream;
            SELECT COUNT(*) INTO var_rem_rows FROM rem_upstream;
            
            RAISE NOTICE 'ReconcileMUpstream: Delta - Adding % rows, Removing % rows', 
                         var_add_rows, var_rem_rows;
            
            -- ===========================================================
            -- STEP 10: Apply ADD changes
            -- ===========================================================
            IF var_add_rows > 0 THEN
                INSERT INTO perseus_dbo.m_upstream (start_point, end_point, path, level)
                SELECT start_point, end_point, path, level
                FROM add_upstream;
                
                RAISE NOTICE 'ReconcileMUpstream: Inserted % new rows', var_add_rows;
            END IF;
            
            -- ===========================================================
            -- STEP 11: Apply REMOVE changes
            -- ===========================================================
            IF var_rem_rows > 0 THEN
                DELETE FROM perseus_dbo.m_upstream
                WHERE start_point IN (
                    SELECT uid FROM "var_dirty$aws$tmp"
                )
                AND NOT EXISTS (
                    SELECT 1 
                    FROM new_upstream AS n
                    WHERE n.start_point = m_upstream.start_point
                      AND n.end_point = m_upstream.end_point
                      AND n.path = m_upstream.path
                );
                
                RAISE NOTICE 'ReconcileMUpstream: Deleted % obsolete rows', var_rem_rows;
            END IF;
            
        ELSE
            RAISE NOTICE 'ReconcileMUpstream: No dirty materials found, skipping processing';
        END IF;
        
        -- ===============================================================
        -- SUCCESS: Log execution time
        -- ===============================================================
        var_end_time := clock_timestamp();
        var_execution_time := EXTRACT(MILLISECONDS FROM (var_end_time - var_start_time));
        
        RAISE NOTICE 'ReconcileMUpstream: Completed successfully in % ms', var_execution_time;
        
        -- Optional: Insert into audit table
        -- INSERT INTO perseus_dbo.procedure_audit_log 
        --     (procedure_name, status, rows_affected, execution_time_ms)
        -- VALUES 
        --     ('ReconcileMUpstream', 'SUCCESS', var_add_rows + var_rem_rows, var_execution_time);
        
    EXCEPTION
        WHEN OTHERS THEN
            -- ===============================================================
            -- ERROR HANDLING: Capture details and rollback
            -- ===============================================================
            ROLLBACK;  -- Now works correctly with BEGIN block
            
            -- Get error details
            GET STACKED DIAGNOSTICS 
                var_ErrorState = RETURNED_SQLSTATE,
                var_ErrorMessage = MESSAGE_TEXT;
            
            -- Log error
            RAISE WARNING 'ReconcileMUpstream: Failed with SQLSTATE % - %', 
                          var_ErrorState, var_ErrorMessage;
            
            -- Optional: Insert into audit table
            -- INSERT INTO perseus_dbo.procedure_audit_log 
            --     (procedure_name, status, error_message)
            -- VALUES 
            --     ('ReconcileMUpstream', 'FAILED', var_ErrorMessage);
            
            -- Re-raise error with proper format
            RAISE EXCEPTION 'ReconcileMUpstream failed: % (SQLSTATE: %)', 
                  var_ErrorMessage, var_ErrorState
                  USING ERRCODE = 'P0001',
                        HINT = 'Check m_upstream and m_upstream_dirty_leaves tables for data consistency',
                        DETAIL = 'Procedure: RECONCILEMUPSTREAM';
            
    END;  -- End of transaction block
    
    -- Note: Temp tables with ON COMMIT DROP will be auto-cleaned here
    
END;
$BODY$
LANGUAGE plpgsql;

-- ===================================================================
-- INDEXES FOR PERFORMANCE (if LOWER() is needed)
-- ===================================================================
-- Uncomment if you decide to keep LOWER() in queries

-- CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_upstream_start_lower 
-- ON perseus_dbo.m_upstream (LOWER(start_point))
-- WHERE start_point IS NOT NULL;

-- CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_upstream_end_lower 
-- ON perseus_dbo.m_upstream (LOWER(end_point))
-- WHERE end_point IS NOT NULL;

-- CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_dirty_leaves_uid_lower
-- ON perseus_dbo.m_upstream_dirty_leaves (LOWER(material_uid))
-- WHERE material_uid IS NOT NULL;

-- ===================================================================
-- STANDARD INDEXES FOR PERFORMANCE (without LOWER)
-- ===================================================================
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_upstream_composite
ON perseus_dbo.m_upstream (start_point, end_point, path);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_dirty_leaves_uid
ON perseus_dbo.m_upstream_dirty_leaves (material_uid)
WHERE material_uid != 'n/a';

-- Analyze tables after creating indexes
ANALYZE perseus_dbo.m_upstream;
ANALYZE perseus_dbo.m_upstream_dirty_leaves;

-- ===================================================================
-- GRANT PERMISSIONS
-- ===================================================================
-- GRANT EXECUTE ON PROCEDURE perseus_dbo.reconcilemupstream TO your_role;

-- ===================================================================
-- TESTING QUERIES
-- ===================================================================
-- Test procedure execution
-- CALL perseus_dbo.reconcilemupstream();

-- Check audit logs (if implemented)
-- SELECT * FROM perseus_dbo.procedure_audit_log 
-- WHERE procedure_name = 'ReconcileMUpstream'
-- ORDER BY execution_timestamp DESC;

-- Check temp table cleanup (should return 0 rows after procedure completes)
-- SELECT * FROM pg_tables WHERE schemaname LIKE 'pg_temp_%';

-- ===================================================================
-- END OF CORRECTED VERSION
-- ===================================================================
```

---

## üèÅ Final Notes

Este relat√≥rio fornece uma an√°lise completa e acion√°vel da convers√£o realizada pela AWS Schema Conversion Tool. O c√≥digo corrigido est√° pronto para testes em ambiente de desenvolvimento.

**Prioridades:**
1. ‚úÖ Aplicar corre√ß√µes P0 (transaction control + RAISE)
2. ‚ö†Ô∏è Avaliar necessidade de LOWER() com dados reais
3. üí° Considerar melhorias P1/P2 conforme tempo dispon√≠vel

**Pr√≥ximos Passos Recomendados:**
- Aplicar c√≥digo corrigido em DEV
- Executar testes com dados reais
- Medir performance (antes vs depois)
- Validar comportamento de erro
- Documentar mudan√ßas para equipe
- Replicar padr√µes de corre√ß√£o para outras procedures

---

**Document Version:** 1.0  
**Last Updated:** 2025-11-12  
**Reviewed By:** Pierre Ribeiro (Database Reliability Engineer)  
**Status:** ‚úÖ READY FOR DEV DEPLOYMENT (ap√≥s aplicar corre√ß√µes P0)
